<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Deploying Kubernetes on VMs with Kubespray | Dicking with Docker</title>
<meta name="keywords" content="ansible, automation, config-management, deployment, kubernetes, orchestration">
<meta name="description" content="All the choices So you&rsquo;re looking to start using Kubernetes, but you&rsquo;re overwhelmed by the multitude of deployment options available? Judging by the length of the Picking the Right Solution section to the Kubernetes docs, it&rsquo;s safe to assume that you&rsquo;re not alone. Even after you&rsquo;ve made it past the provisioning stage, you then need to learn how to administrate what is a very complex system. In short; Kubernetes is not easy.">
<meta name="author" content="Simon Weald">
<link rel="canonical" href="https://dickingwithdocker.com/posts/deploying-kubernetes-vms-kubespray/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.9329d037bc79464b26647fb72e079cd738f5d2418b1df4da3b515db9e22cb4d9.css" integrity="sha256-kynQN7x5RksmZH&#43;3Lgec1zj10kGLHfTaO1FdueIstNk=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://dickingwithdocker.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://dickingwithdocker.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://dickingwithdocker.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://dickingwithdocker.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://dickingwithdocker.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Deploying Kubernetes on VMs with Kubespray" />
<meta property="og:description" content="All the choices So you&rsquo;re looking to start using Kubernetes, but you&rsquo;re overwhelmed by the multitude of deployment options available? Judging by the length of the Picking the Right Solution section to the Kubernetes docs, it&rsquo;s safe to assume that you&rsquo;re not alone. Even after you&rsquo;ve made it past the provisioning stage, you then need to learn how to administrate what is a very complex system. In short; Kubernetes is not easy." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://dickingwithdocker.com/posts/deploying-kubernetes-vms-kubespray/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2017-08-09T00:00:00+00:00" />
<meta property="article:modified_time" content="2017-08-09T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Deploying Kubernetes on VMs with Kubespray"/>
<meta name="twitter:description" content="All the choices So you&rsquo;re looking to start using Kubernetes, but you&rsquo;re overwhelmed by the multitude of deployment options available? Judging by the length of the Picking the Right Solution section to the Kubernetes docs, it&rsquo;s safe to assume that you&rsquo;re not alone. Even after you&rsquo;ve made it past the provisioning stage, you then need to learn how to administrate what is a very complex system. In short; Kubernetes is not easy."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://dickingwithdocker.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Deploying Kubernetes on VMs with Kubespray",
      "item": "https://dickingwithdocker.com/posts/deploying-kubernetes-vms-kubespray/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Deploying Kubernetes on VMs with Kubespray",
  "name": "Deploying Kubernetes on VMs with Kubespray",
  "description": "All the choices So you\u0026rsquo;re looking to start using Kubernetes, but you\u0026rsquo;re overwhelmed by the multitude of deployment options available? Judging by the length of the Picking the Right Solution section to the Kubernetes docs, it\u0026rsquo;s safe to assume that you\u0026rsquo;re not alone. Even after you\u0026rsquo;ve made it past the provisioning stage, you then need to learn how to administrate what is a very complex system. In short; Kubernetes is not easy.",
  "keywords": [
    "ansible", "automation", "config-management", "deployment", "kubernetes", "orchestration"
  ],
  "articleBody": "All the choices So you’re looking to start using Kubernetes, but you’re overwhelmed by the multitude of deployment options available? Judging by the length of the Picking the Right Solution section to the Kubernetes docs, it’s safe to assume that you’re not alone. Even after you’ve made it past the provisioning stage, you then need to learn how to administrate what is a very complex system. In short; Kubernetes is not easy.\nNaturally then, the easiest way to use Kubernetes is to let someone else look after the infrastructure for you. If you’re looking for the most hands-off turnkey solution then you should investigate Google’s Container Engine, or RedHat’s OpenShift Dedicated platform.\nWhilst these solutions do make it easier to consume Kubernetes for your workloads by abstracting away the management overheads, you may well need to maintain greater control over your data. Whilst using the cloud is perfectly safe, this may not be something your security controls permit, making cloud-hosted options such as those mentioned above unviable. In these cases, unless you have a large budget to spend on something like RedHat’s on-premise Container Platform, you’ll need to look at rolling your own.\nAt this point, picking the right solution has become a little easier. As with all open-source projects, it’s important to judge their suitability - you don’t want to adopt an unmaintained project unless you have the time and resources to maintain it yourself. This is especially important when interacting with Kubernetes, as the development moves fast and new features are added regularly.\nWith all this in mind, I ended up settling on Kubespray (originally called Kargo). Kubespray is a Kubernetes incubator project, which means it is on its way to becoming a fully-fledged community project. I spend a fair bit of my own time working with Ansible, and as Kubespray is just a large set of playbooks, it was the obvious choice.\nGetting started The rest of this post assumes that your target hosts are already correctly configured for administration via Ansible - if you’re starting off with virgin nodes then you can use something like my Ansible node bootstrapping playbook. Obviously this still requires access of some fashion; in my case my hosting provider Memset gives you the ability to inject an SSH key at provisioning time. Once this is in place I can run my playbook to reconfigure the node as I see fit.\nConfiguring your hosts file Now you’re ready to start, you’ll obviously need to clone the Kubespray repo. Once you’ve done this, duplicate the inventory directory and jump there. You’ll need to configure your inventory file to suit your deployment; below is mine for illustration’s sake:\n[all] node1 ansible_ssh_host=1.2.3.1 ip=10.1.205.11 node2 ansible_ssh_host=1.2.3.2 ip=10.1.205.12 node3 ansible_ssh_host=1.2.3.3 ip=10.1.205.13 node4 ansible_ssh_host=1.2.3.4 ip=10.1.205.14 node5 ansible_ssh_host=1.2.3.5 ip=10.1.205.15 [kube-master] node1 node2 [kube-node] node1 node2 node3 node4 node5 [etcd] node3 node4 node5 [k8s-cluster:children] kube-node kube-master [calico-rr] The [all] group needs to contain all nodes in the cluster. If you wish to have them communicate over a different IP to the access IP then you can specify this using the ip variable. In my case, I have a VLAN between all 5 nodes and I want my internal cluster traffic to traverse this, rather than the public internet.\nThe nodes listed under the [kube-master] heading will become cluster masters who’s job is to modify the cluster’s state by scheduling pods etc. For HA purposes, it’s a good idea to have more than one.\nAny node in the kube-node group will be available for scheduling pods onto. In a larger cluster these nodes will purely function as minions, however in my case my masters are also minions too.\nFinally, the [etcd] group tells Ansible which nodes to deploy your etcd cluster onto. Kubernetes stores a lot of information in etcd so three nodes is good practise. You could run with a single etcd node, but if that goes away then the entire cluster will grind to a halt.\nGlobal config options Contained within your duplicated inventory directory is a group_vars directory. Assuming you’re familiar with Ansible the purpose of this directory is clear. Unless you require some edge cases, the majority of all.yml can remain as provided:\n# Valid bootstrap options (required): ubuntu, coreos, centos, none bootstrap_os: ubuntu ### OTHER OPTIONAL VARIABLES ## For some things, kubelet needs to load kernel modules. For example, dynamic kernel services are needed ## for mounting persistent volumes into containers. These may not be loaded by preinstall kubernetes ## processes. For example, ceph and rbd backed volumes. Set to true to allow kubelet to load kernel ## modules. kubelet_load_modules: true Nothing too complicated going on here; one thing to bear in mind here is that the module loading isn’t persistent. Ansible will modprobe any modules Kubernetes needs, but this won’t survive a reboot (as I discovered the hard way).\nCluster config options The k8s-cluster.yml file requires a little more customisation. Firstly, I’d suggest disabling anonymous authentication to the API for security reasons. You then need to pick the version of Kubernetes to deploy, and set some passwords:\nkube_api_anonymous_auth: false ## Change this to use another Kubernetes version, e.g. a current beta release kube_version: v1.6.7 # Users to create for basic auth in Kubernetes API via HTTP kube_api_pwd: \"YOUR PASSWORD HERE\" kube_users: kube: pass: \"{{kube_api_pwd}}\" role: admin root: pass: \"{{kube_api_pwd}}\" role: admin Next up, some networking config. As is to be expected, there are a multitude of options when it comes to setting up networking in Kubernetes. Kubespray gives you a subset of these options; I chose to go with Weave as it means I can deploy Weave Scope at a later date.\n# Choose network plugin (calico, weave or flannel) # Can also be set to 'cloud', which lets the cloud provider setup appropriate routing kube_network_plugin: weave # Kubernetes internal network for services, unused block of space. kube_service_addresses: 10.233.0.0/18 # internal network. When used, it will assign IP # addresses from this range to individual pods. # This network must be unused in your network infrastructure! kube_pods_subnet: 10.240.00.0/18 Lastly, we have some options it’s worth enabling which help visualise the state of your cluster. The Netchecker deployment places pods on all hosts which constantly verify the state of the networking by attempting to communicate with each other.\n# Deploy netchecker app to verify DNS resolve as an HTTP service deploy_netchecker: true # Monitoring apps for k8s efk_enabled: true Deployment With everything configured to your liking, it’s time to deploy to your nodes. In the root of the Kubespray checkout is cluster.yml; this is what we’ll need to use. Deployment is carried out the usual Ansible way:\n$ ansible-playbook -i kube_cluster/hosts cluster.yml -b -v The run-time of this playbook is very much dependent on a number of variables, such as the number of nodes and also how much Internet-connected bandwidth they have; for my nodes, it took around 20 minutes.\nAccessing your cluster Before you can use your cluster, you need to configure access to it. During the cluster bootstrapping process, various SSL certificates will have been created which we can use to authenticate ourselves. From your master node in /etc/kubernetes/ssl you’ll need to grab a copy of the node’s admin certificate, the corresponding private key, and the CA certificate. You’ll need to place these in /home/user/.kube/ on the machine you wish to use to administrate the cluster, along with a config file pointing to them:\n$ cat .kube/config apiVersion: v1 clusters: - cluster: certificate-authority: /home/user/.kube/ca.pem server: https://kubernetes.default:6443 name: kargo contexts: - context: cluster: kargo user: admin name: kargo current-context: kargo kind: Config preferences: {} users: - name: admin user: client-certificate: /home/user/.kube/admin-node1.pem client-key: /home/user/.kube/admin-node1-key.pem Finally, ensure the server: variable is a URL by which you can talk to your master node.\nVerify the cluster state At this point, you should be able to run kubectl get pods -o wide --all-namespaces (note that you may see more or less pods if you chose different options in your config).\nNAMESPACE NAME READY STATUS RESTARTS AGE IP NODE default netchecker-agent-7bnqq 1/1 Running 0 13d 10.240.26.1 node3 default netchecker-agent-hostnet-4xhlc 1/1 Running 1 14d 10.1.205.14 node5 default netchecker-agent-hostnet-gb2wf 1/1 Running 1 14d 10.1.205.11 node2 default netchecker-agent-hostnet-ld44s 1/1 Running 1 14d 10.1.205.10 node1 default netchecker-agent-hostnet-xw5r2 1/1 Running 1 14d 10.1.205.12 node3 default netchecker-agent-hostnet-zdxrz 1/1 Running 1 14d 10.1.205.13 node4 default netchecker-agent-nhlkp 1/1 Running 0 13d 10.240.10.1 node4 default netchecker-agent-qr5zg 1/1 Running 0 13d 10.240.14.0 node2 default netchecker-agent-xs8xm 1/1 Running 0 13d 10.240.8.1 node5 default netchecker-agent-ztp40 1/1 Running 0 13d 10.240.30.0 node1 default netchecker-server-3646041304-gzl3m 1/1 Running 18 13d 10.240.8.4 node5 kube-system kube-apiserver-node1 1/1 Running 1 13d 10.1.205.10 node1 kube-system kube-apiserver-node2 1/1 Running 1 13d 10.1.205.11 node2 kube-system kube-controller-manager-node1 1/1 Running 2 13d 10.1.205.10 node1 kube-system kube-controller-manager-node2 1/1 Running 1 13d 10.1.205.11 node2 kube-system kube-dns-3841192733-7nbbx 3/3 Running 1 13d 10.240.8.5 node5 kube-system kube-dns-3841192733-7zg62 3/3 Running 0 13d 10.240.26.4 node3 kube-system kube-proxy-node1 1/1 Running 1 13d 10.1.205.10 node1 kube-system kube-proxy-node2 1/1 Running 1 13d 10.1.205.11 node2 kube-system kube-proxy-node3 1/1 Running 1 13d 10.1.205.12 node3 kube-system kube-proxy-node4 1/1 Running 1 13d 10.1.205.13 node4 kube-system kube-proxy-node5 1/1 Running 1 13d 10.1.205.14 node5 kube-system kube-scheduler-node1 1/1 Running 3 13d 10.1.205.10 node1 kube-system kube-scheduler-node2 1/1 Running 2 13d 10.1.205.11 node2 kube-system kubedns-autoscaler-1833630871-rznl5 1/1 Running 0 13d 10.240.26.3 node3 kube-system kubernetes-dashboard-2039414953-s4ts8 1/1 Running 5 13d 10.240.8.6 node5 kube-system monitoring-grafana-2527507788-5cbbd 1/1 Running 0 11d 10.240.14.2 node2 kube-system monitoring-influxdb-3480804314-6zw45 1/1 Running 0 11d 10.240.10.3 node4 kube-system nginx-proxy-node3 1/1 Running 1 13d 10.1.205.12 node3 kube-system nginx-proxy-node4 1/1 Running 1 13d 10.1.205.13 node4 kube-system nginx-proxy-node5 1/1 Running 1 13d 10.1.205.14 node5 kube-system weave-net-2t7jp 2/2 Running 2 14d 10.1.205.14 node5 kube-system weave-net-45h6g 2/2 Running 2 14d 10.1.205.10 node1 kube-system weave-net-c6bbl 2/2 Running 3 14d 10.1.205.13 node4 kube-system weave-net-lh6x2 2/2 Running 2 14d 10.1.205.11 node2 kube-system weave-net-s43ct 2/2 Running 2 14d 10.1.205.12 node3 Provided all pods are listed as running then you should have a healthy cluster. The most complete way to administrate your cluster is using kubectl, however it’s not great for at-a-glance monitoring. Fortunately, Kubernetes has you covered with their dashboard. You can deploy it straight from the git repo:\n$ kubectl create -f https://git.io/kube-dashboard With that done, you will need to grab a terminal as you’ll use kubectl to proxy the dashboard from the cluster:\n$ kubectl proxy Starting to serve on 127.0.0.1:8001 Finally, open your favourite browser and head to http://localhost:8001/ui and you should see the dashboard. Success!\nBonus round If you went with Weave for your networking, you can also deploy Weave Scope which gives you a great deal of insight into your cluster. Unsurprisingly, we deploy on top of Kubernetes which means no need to configure anything - Weave will automatically provide the metrics to the Scope pods.\n$ kubectl apply --namespace kube-system -f \"https://cloud.weave.works/k8s/scope.yaml?k8s-version=$(kubectl version | base64 | tr -d '\\\\n')\" With that done, you’ll then use kubectl to forward the relevant port:\n$ kubectl port-forward -n kube-system \"$(kubectl get -n kube-system pod --selector=weave-scope-component=app -o jsonpath='{.items..metadata.name}')\" 4040 And then as for the dashboard, open up your browser and navigate to http://127.0.0.1:4040.\n",
  "wordCount" : "1822",
  "inLanguage": "en",
  "datePublished": "2017-08-09T00:00:00Z",
  "dateModified": "2017-08-09T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Simon Weald"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://dickingwithdocker.com/posts/deploying-kubernetes-vms-kubespray/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Dicking with Docker",
    "logo": {
      "@type": "ImageObject",
      "url": "https://dickingwithdocker.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://dickingwithdocker.com/" accesskey="h" title="Dicking with Docker (Alt + H)">Dicking with Docker</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://dickingwithdocker.com/categories/" title="categories">
                    <span>categories</span>
                </a>
            </li>
            <li>
                <a href="https://dickingwithdocker.com/tags/" title="tags">
                    <span>tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://dickingwithdocker.com/">Home</a>&nbsp;»&nbsp;<a href="https://dickingwithdocker.com/posts/">Posts</a></div>
    <h1 class="post-title">
      Deploying Kubernetes on VMs with Kubespray
    </h1>
    <div class="post-meta"><span title='2017-08-09 00:00:00 +0000 UTC'>August 9, 2017</span>&nbsp;·&nbsp;9 min&nbsp;·&nbsp;Simon Weald

</div>
  </header> 
  <div class="post-content"><h3 id="all-the-choices">All the choices<a hidden class="anchor" aria-hidden="true" href="#all-the-choices">#</a></h3>
<p>So you&rsquo;re looking to start using Kubernetes, but you&rsquo;re overwhelmed by the multitude of deployment options available? Judging by the length of the <a href="https://kubernetes.io/docs/setup/pick-right-solution/">Picking the Right Solution</a> section to the Kubernetes docs, it&rsquo;s safe to assume that you&rsquo;re not alone. Even after you&rsquo;ve made it past the provisioning stage, you then need to learn how to administrate what is a very complex system. In short; Kubernetes is not easy.</p>
<p>Naturally then, the easiest way to use Kubernetes is to let someone else look after the infrastructure for you. If you&rsquo;re looking for the most hands-off turnkey solution then you should investigate Google&rsquo;s <a href="https://cloud.google.com/container-engine/">Container Engine</a>, or RedHat&rsquo;s <a href="https://www.openshift.com/dedicated/">OpenShift Dedicated</a> platform.</p>
<p>Whilst these solutions do make it easier to consume Kubernetes for your workloads by abstracting away the management overheads, you may well need to maintain greater control over your data. Whilst using the cloud is perfectly safe, this may not be something your security controls permit, making cloud-hosted options such as those mentioned above unviable. In these cases, unless you have a large budget to spend on something like RedHat&rsquo;s <a href="https://www.openshift.com/container-platform/">on-premise Container Platform</a>, you&rsquo;ll need to look at rolling your own.</p>
<p>At this point, <a href="https://kubernetes.io/docs/setup/pick-right-solution/">picking the right solution</a> has become a <em>little</em> easier. As with all open-source projects, it&rsquo;s important to judge their suitability - you don&rsquo;t want to adopt an unmaintained project unless you have the time and resources to maintain it yourself. This is especially important when interacting with Kubernetes, as the development moves fast and new features are added regularly.</p>
<p>With all this in mind, I ended up settling on <a href="https://github.com/kubernetes-incubator/kubespray">Kubespray</a> (originally called Kargo). Kubespray is a Kubernetes <a href="https://github.com/kubernetes/community/blob/master/incubator.md">incubator</a> project, which means it is on its way to becoming a fully-fledged community project. I spend a fair bit of my own time working with Ansible, and as Kubespray is just a large set of playbooks, it was the obvious choice.</p>
<h3 id="getting-started">Getting started<a hidden class="anchor" aria-hidden="true" href="#getting-started">#</a></h3>
<p>The rest of this post assumes that your target hosts are already correctly configured for administration via Ansible - if you&rsquo;re starting off with virgin nodes then you can use something like my <a href="http://dickingwithdocker.com/2017/08/ansible-node-bootstrapping/">Ansible node bootstrapping</a> playbook. Obviously this still requires access of some fashion; in my case my hosting provider <a href="https://www.memset.com">Memset</a> gives you the ability to inject an SSH key at provisioning time. Once this is in place I can run my playbook to reconfigure the node as I see fit.</p>
<h5 id="configuring-your-hosts-file">Configuring your hosts file<a hidden class="anchor" aria-hidden="true" href="#configuring-your-hosts-file">#</a></h5>
<p>Now you&rsquo;re ready to start, you&rsquo;ll obviously need to clone the Kubespray repo. Once you&rsquo;ve done this, duplicate the inventory directory and jump there. You&rsquo;ll need to configure your inventory file to suit your deployment; below is mine for illustration&rsquo;s sake:</p>
<pre tabindex="0"><code>[all]
node1   ansible_ssh_host=1.2.3.1    ip=10.1.205.11
node2   ansible_ssh_host=1.2.3.2    ip=10.1.205.12
node3   ansible_ssh_host=1.2.3.3    ip=10.1.205.13
node4   ansible_ssh_host=1.2.3.4    ip=10.1.205.14
node5   ansible_ssh_host=1.2.3.5    ip=10.1.205.15

[kube-master]
node1
node2

[kube-node]
node1
node2
node3
node4
node5

[etcd]
node3
node4
node5

[k8s-cluster:children]
kube-node
kube-master

[calico-rr]
</code></pre><p>The <code>[all]</code> group needs to contain all nodes in the cluster. If you wish to have them communicate over a different IP to the access IP then you can specify this using the <code>ip</code> variable. In my case, I have a VLAN between all 5 nodes and I want my internal cluster traffic to traverse this, rather than the public internet.</p>
<p>The nodes listed under the <code>[kube-master]</code> heading will become cluster <a href="https://kubernetes.io/docs/admin/high-availability/#master-elected-components">masters</a> who&rsquo;s job is to modify the cluster&rsquo;s state by scheduling pods etc. For HA purposes, it&rsquo;s a good idea to have more than one.</p>
<p>Any node in the <code>kube-node</code> group will be available for scheduling pods onto. In a larger cluster these nodes will purely function as minions, however in my case my masters are also minions too.</p>
<p>Finally, the <code>[etcd]</code> group tells Ansible which nodes to deploy your <a href="https://github.com/coreos/etcd">etcd</a> cluster onto. Kubernetes stores a lot of information in etcd so three nodes is good practise. You could run with a single etcd node, but if that goes away then the entire cluster will grind to a halt.</p>
<h5 id="global-config-options">Global config options<a hidden class="anchor" aria-hidden="true" href="#global-config-options">#</a></h5>
<p>Contained within your duplicated inventory directory is a <code>group_vars</code> directory. Assuming you&rsquo;re familiar with Ansible the purpose of this directory is clear. Unless you require some edge cases, the majority of <code>all.yml</code> can remain as provided:</p>
<pre tabindex="0"><code># Valid bootstrap options (required): ubuntu, coreos, centos, none
bootstrap_os: ubuntu

### OTHER OPTIONAL VARIABLES
## For some things, kubelet needs to load kernel modules.  For example, dynamic kernel services are needed
## for mounting persistent volumes into containers.  These may not be loaded by preinstall kubernetes
## processes.  For example, ceph and rbd backed volumes.  Set to true to allow kubelet to load kernel
## modules.
kubelet_load_modules: true
</code></pre><p>Nothing too complicated going on here; one thing to bear in mind here is that the module loading isn&rsquo;t persistent. Ansible will modprobe any modules Kubernetes needs, but this won&rsquo;t survive a reboot (as I discovered the hard way).</p>
<h5 id="cluster-config-options">Cluster config options<a hidden class="anchor" aria-hidden="true" href="#cluster-config-options">#</a></h5>
<p>The <code>k8s-cluster.yml</code> file requires a little more customisation. Firstly, I&rsquo;d suggest disabling anonymous authentication to the API for security reasons. You then need to pick the version of Kubernetes to deploy, and set some passwords:</p>
<pre tabindex="0"><code>kube_api_anonymous_auth: false

## Change this to use another Kubernetes version, e.g. a current beta release
kube_version: v1.6.7

# Users to create for basic auth in Kubernetes API via HTTP
kube_api_pwd: &#34;YOUR PASSWORD HERE&#34;
kube_users:
  kube:
    pass: &#34;{{kube_api_pwd}}&#34;
    role: admin
  root:
    pass: &#34;{{kube_api_pwd}}&#34;
    role: admin
</code></pre><p>Next up, some networking config. As is to be expected, there are a multitude of options when it comes to setting up <a href="https://kubernetes.io/docs/concepts/cluster-administration/networking/">networking in Kubernetes</a>. Kubespray gives you a subset of these options; I chose to go with <a href="https://www.weave.works/docs/net/latest/overview/">Weave</a> as it means I can deploy <a href="https://www.weave.works/oss/scope/">Weave Scope</a> at a later date.</p>
<pre tabindex="0"><code># Choose network plugin (calico, weave or flannel)
# Can also be set to &#39;cloud&#39;, which lets the cloud provider setup appropriate routing
kube_network_plugin: weave

# Kubernetes internal network for services, unused block of space.
kube_service_addresses: 10.233.0.0/18

# internal network. When used, it will assign IP
# addresses from this range to individual pods.
# This network must be unused in your network infrastructure!
kube_pods_subnet: 10.240.00.0/18
</code></pre><p>Lastly, we have some options it&rsquo;s worth enabling which help visualise the state of your cluster. The <a href="https://github.com/kubernetes-incubator/kubespray/blob/master/docs/netcheck.md">Netchecker</a> deployment places pods on all hosts which constantly verify the state of the networking by attempting to communicate with each other.</p>
<pre tabindex="0"><code># Deploy netchecker app to verify DNS resolve as an HTTP service
deploy_netchecker: true

# Monitoring apps for k8s
efk_enabled: true
</code></pre><h3 id="deployment">Deployment<a hidden class="anchor" aria-hidden="true" href="#deployment">#</a></h3>
<p>With everything configured to your liking, it&rsquo;s time to deploy to your nodes. In the root of the Kubespray checkout is <code>cluster.yml</code>; this is what we&rsquo;ll need to use. Deployment is carried out the usual Ansible way:</p>
<pre tabindex="0"><code>$ ansible-playbook -i kube_cluster/hosts cluster.yml -b -v
</code></pre><p>The run-time of this playbook is very much dependent on a number of variables, such as the number of nodes and also how much Internet-connected bandwidth they have; for my nodes, it took around 20 minutes.</p>
<h3 id="accessing-your-cluster">Accessing your cluster<a hidden class="anchor" aria-hidden="true" href="#accessing-your-cluster">#</a></h3>
<p>Before you can use your cluster, you need to configure access to it. During the cluster bootstrapping process, various SSL certificates will have been created which we can use to authenticate ourselves. From your master node in <code>/etc/kubernetes/ssl</code> you&rsquo;ll need to grab a copy of the node&rsquo;s admin certificate, the corresponding private key, and the CA certificate. You&rsquo;ll need to place these in <code>/home/user/.kube/</code> on the machine you wish to use to administrate the cluster, along with a config file pointing to them:</p>
<pre tabindex="0"><code>$ cat .kube/config
apiVersion: v1
clusters:
- cluster:
    certificate-authority: /home/user/.kube/ca.pem
    server: https://kubernetes.default:6443
  name: kargo
contexts:
- context:
    cluster: kargo
    user: admin
  name: kargo
current-context: kargo
kind: Config
preferences: {}
users:
- name: admin
  user:
    client-certificate: /home/user/.kube/admin-node1.pem
    client-key: /home/user/.kube/admin-node1-key.pem
</code></pre><p>Finally, ensure the <code>server:</code> variable is a URL by which you can talk to your master node.</p>
<h5 id="verify-the-cluster-state">Verify the cluster state<a hidden class="anchor" aria-hidden="true" href="#verify-the-cluster-state">#</a></h5>
<p>At this point, you should be able to run <code>kubectl get pods -o wide --all-namespaces</code> (note that you may see more or less pods if you chose different options in your config).</p>
<pre tabindex="0"><code>NAMESPACE     NAME                                    READY     STATUS    RESTARTS   AGE       IP            NODE
default       netchecker-agent-7bnqq                  1/1       Running   0          13d       10.240.26.1   node3
default       netchecker-agent-hostnet-4xhlc          1/1       Running   1          14d       10.1.205.14   node5
default       netchecker-agent-hostnet-gb2wf          1/1       Running   1          14d       10.1.205.11   node2
default       netchecker-agent-hostnet-ld44s          1/1       Running   1          14d       10.1.205.10   node1
default       netchecker-agent-hostnet-xw5r2          1/1       Running   1          14d       10.1.205.12   node3
default       netchecker-agent-hostnet-zdxrz          1/1       Running   1          14d       10.1.205.13   node4
default       netchecker-agent-nhlkp                  1/1       Running   0          13d       10.240.10.1   node4
default       netchecker-agent-qr5zg                  1/1       Running   0          13d       10.240.14.0   node2
default       netchecker-agent-xs8xm                  1/1       Running   0          13d       10.240.8.1    node5
default       netchecker-agent-ztp40                  1/1       Running   0          13d       10.240.30.0   node1
default       netchecker-server-3646041304-gzl3m      1/1       Running   18         13d       10.240.8.4    node5
kube-system   kube-apiserver-node1                    1/1       Running   1          13d       10.1.205.10   node1
kube-system   kube-apiserver-node2                    1/1       Running   1          13d       10.1.205.11   node2
kube-system   kube-controller-manager-node1           1/1       Running   2          13d       10.1.205.10   node1
kube-system   kube-controller-manager-node2           1/1       Running   1          13d       10.1.205.11   node2
kube-system   kube-dns-3841192733-7nbbx               3/3       Running   1          13d       10.240.8.5    node5
kube-system   kube-dns-3841192733-7zg62               3/3       Running   0          13d       10.240.26.4   node3
kube-system   kube-proxy-node1                        1/1       Running   1          13d       10.1.205.10   node1
kube-system   kube-proxy-node2                        1/1       Running   1          13d       10.1.205.11   node2
kube-system   kube-proxy-node3                        1/1       Running   1          13d       10.1.205.12   node3
kube-system   kube-proxy-node4                        1/1       Running   1          13d       10.1.205.13   node4
kube-system   kube-proxy-node5                        1/1       Running   1          13d       10.1.205.14   node5
kube-system   kube-scheduler-node1                    1/1       Running   3          13d       10.1.205.10   node1
kube-system   kube-scheduler-node2                    1/1       Running   2          13d       10.1.205.11   node2
kube-system   kubedns-autoscaler-1833630871-rznl5     1/1       Running   0          13d       10.240.26.3   node3
kube-system   kubernetes-dashboard-2039414953-s4ts8   1/1       Running   5          13d       10.240.8.6    node5
kube-system   monitoring-grafana-2527507788-5cbbd     1/1       Running   0          11d       10.240.14.2   node2
kube-system   monitoring-influxdb-3480804314-6zw45    1/1       Running   0          11d       10.240.10.3   node4
kube-system   nginx-proxy-node3                       1/1       Running   1          13d       10.1.205.12   node3
kube-system   nginx-proxy-node4                       1/1       Running   1          13d       10.1.205.13   node4
kube-system   nginx-proxy-node5                       1/1       Running   1          13d       10.1.205.14   node5
kube-system   weave-net-2t7jp                         2/2       Running   2          14d       10.1.205.14   node5
kube-system   weave-net-45h6g                         2/2       Running   2          14d       10.1.205.10   node1
kube-system   weave-net-c6bbl                         2/2       Running   3          14d       10.1.205.13   node4
kube-system   weave-net-lh6x2                         2/2       Running   2          14d       10.1.205.11   node2
kube-system   weave-net-s43ct                         2/2       Running   2          14d       10.1.205.12   node3
</code></pre><p>Provided all pods are listed as running then you should have a healthy cluster. The most complete way to administrate your cluster is using kubectl, however it&rsquo;s not great for at-a-glance monitoring. Fortunately, Kubernetes has you covered with their dashboard. You can deploy it straight from the git repo:</p>
<pre tabindex="0"><code>$ kubectl create -f https://git.io/kube-dashboard
</code></pre><p>With that done, you will need to grab a terminal as you&rsquo;ll use kubectl to proxy the dashboard from the cluster:</p>
<pre tabindex="0"><code>$ kubectl proxy
Starting to serve on 127.0.0.1:8001
</code></pre><p>Finally, open your favourite browser and head to <a href="http://localhost:8001/ui">http://localhost:8001/ui</a> and you should see the dashboard. Success!</p>
<h3 id="bonus-round">Bonus round<a hidden class="anchor" aria-hidden="true" href="#bonus-round">#</a></h3>
<p>If you went with <a href="https://www.weave.works/docs/net/latest/overview/">Weave</a> for your networking, you can also deploy <a href="https://www.weave.works/oss/scope/">Weave Scope</a> which gives you a great deal of insight into your cluster. Unsurprisingly, we deploy on top of Kubernetes which means no need to configure anything - Weave will automatically provide the metrics to the Scope pods.</p>
<pre tabindex="0"><code>$ kubectl apply --namespace kube-system -f &#34;https://cloud.weave.works/k8s/scope.yaml?k8s-version=$(kubectl version | base64 | tr -d &#39;\\n&#39;)&#34;
</code></pre><p>With that done, you&rsquo;ll then use kubectl to forward the relevant port:</p>
<pre tabindex="0"><code>$ kubectl port-forward -n kube-system &#34;$(kubectl get -n kube-system pod --selector=weave-scope-component=app -o jsonpath=&#39;{.items..metadata.name}&#39;)&#34; 4040
</code></pre><p>And then as for the dashboard, open up your browser and navigate to <a href="http://127.0.0.1:4040">http://127.0.0.1:4040</a>.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://dickingwithdocker.com/tags/ansible/">ansible</a></li>
      <li><a href="https://dickingwithdocker.com/tags/automation/">automation</a></li>
      <li><a href="https://dickingwithdocker.com/tags/config-management/">config-management</a></li>
      <li><a href="https://dickingwithdocker.com/tags/deployment/">deployment</a></li>
      <li><a href="https://dickingwithdocker.com/tags/kubernetes/">kubernetes</a></li>
      <li><a href="https://dickingwithdocker.com/tags/orchestration/">orchestration</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://dickingwithdocker.com/posts/over-engineering-my-website-kubernetes/">
    <span class="title">« Prev</span>
    <br>
    <span>Over-engineering my website with Kubernetes</span>
  </a>
  <a class="next" href="https://dickingwithdocker.com/posts/ansible-node-bootstrapping/">
    <span class="title">Next »</span>
    <br>
    <span>Ansible Node Bootstrapping</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Deploying Kubernetes on VMs with Kubespray on x"
            href="https://x.com/intent/tweet/?text=Deploying%20Kubernetes%20on%20VMs%20with%20Kubespray&amp;url=https%3a%2f%2fdickingwithdocker.com%2fposts%2fdeploying-kubernetes-vms-kubespray%2f&amp;hashtags=ansible%2cautomation%2cconfig-management%2cdeployment%2ckubernetes%2corchestration">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Deploying Kubernetes on VMs with Kubespray on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fdickingwithdocker.com%2fposts%2fdeploying-kubernetes-vms-kubespray%2f&amp;title=Deploying%20Kubernetes%20on%20VMs%20with%20Kubespray&amp;summary=Deploying%20Kubernetes%20on%20VMs%20with%20Kubespray&amp;source=https%3a%2f%2fdickingwithdocker.com%2fposts%2fdeploying-kubernetes-vms-kubespray%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Deploying Kubernetes on VMs with Kubespray on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fdickingwithdocker.com%2fposts%2fdeploying-kubernetes-vms-kubespray%2f&title=Deploying%20Kubernetes%20on%20VMs%20with%20Kubespray">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Deploying Kubernetes on VMs with Kubespray on whatsapp"
            href="https://api.whatsapp.com/send?text=Deploying%20Kubernetes%20on%20VMs%20with%20Kubespray%20-%20https%3a%2f%2fdickingwithdocker.com%2fposts%2fdeploying-kubernetes-vms-kubespray%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Deploying Kubernetes on VMs with Kubespray on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Deploying%20Kubernetes%20on%20VMs%20with%20Kubespray&u=https%3a%2f%2fdickingwithdocker.com%2fposts%2fdeploying-kubernetes-vms-kubespray%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer><div id="disqus_thread"></div>
<script type="application/javascript">
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "dickingwithdocker" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://dickingwithdocker.com/">Dicking with Docker</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
